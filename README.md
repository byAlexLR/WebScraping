# ğŸ–¥ï¸ Web Scraping - Alejandro & Larian

## ğŸ“Œ Cronograma del Proyecto: MonitorizaciÃ³n de Precios

| **SesiÃ³n** | **Actividades**                                                                                       | **DuraciÃ³n Estimada** | **Hecho** |
|------------|-------------------------------------------------------------------------------------------------------|-----------------------|-----------------------|
| **SesiÃ³n 1** | - ConfiguraciÃ³n del entorno de desarrollo. <br> - CreaciÃ³n de la estructura bÃ¡sica del proyecto. <br> - RealizaciÃ³n de solicitudes HTTP. <br> - VerificaciÃ³n de la obtenciÃ³n de HTML. | 6 Feb | **Hecho** |
| **SesiÃ³n 2** | - ImplementaciÃ³n de lÃ³gica para parsear HTML. <br> - Uso de librerÃ­as para extracciÃ³n de datos. <br> - VerificaciÃ³n de extracciÃ³n de datos. | 12 Feb | **Hecho** |
| **SesiÃ³n 3** | - Almacenamiento de datos (CSV/JSON). <br> - ImplementaciÃ³n de actualizaciÃ³n periÃ³dica. <br> - VerificaciÃ³n del almacenamiento y actualizaciÃ³n de datos. | 13 Feb | **Hecho** |
| **SesiÃ³n 4** | - IntegraciÃ³n de todas las partes del proyecto. <br> - Manejo de errores y validaciones. <br> - Pruebas de flujo completo y simulaciÃ³n de fallos. | 19 Feb | **Hecho** |
| **SesiÃ³n 5** | - DocumentaciÃ³n en el archivo `README.md`. <br> - Pruebas finales y presentaciÃ³n. <br> - DemostraciÃ³n del scraper en funcionamiento. | 20 Feb | **Hecho** |

## ğŸ“‚ Estructura del Proyecto
```
WebScraping/
â”‚â”€â”€ README.md                    # DocumentaciÃ³n del proyecto
â”‚â”€â”€ pom.xml                      # Dependencias
â”‚â”€â”€ src/main/java/com/mycompany/webscraping   
â”‚   â”œâ”€â”€ PriceMonitor.java        # CÃ³digo fuente del proyecto
â”‚â”€â”€ output/                      
â”‚   â”œâ”€â”€ result.json              # Archivo que guarda los resultados en JSON
â”‚   â”œâ”€â”€ result.csv               # Archivo que guarda los resultados en CSV
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas
- **Java** como lenguaje principal.
- **Maven** para la gestiÃ³n de dependencias.
- **Jsoup** para el web scraping.
- **JSON y CSV** para almacenamiento de datos.
- **Logger** para manejo de logs y excepciones.

## ğŸš€ Instrucciones para Ejecutarlo
1. Clonar el repositorio:  
   ```sh
   git clone https://github.com/byAlexLR/WebScraping.git
   ```
2. Navegar al directorio del proyecto:
   ```sh
   cd webscraping
   ```
3. Compilar y ejecutar con Maven:
   ```sh
   mvn clean install
   mvn exec:java
   ```
4. Los datos extraÃ­dos se almacenarÃ¡n en:
   - **JSON:** `output/result.json`
   - **CSV:** `output/result.csv`

## ğŸ¤– Uso de IA en el Proyecto
Para desarrollar este proyecto, hemos utilizado inteligencia artificial de generaciÃ³n de cÃ³digo, especÃ­ficamente ChatGPT. La IA fue utilizada en los siguientes aspectos:
- **GeneraciÃ³n de cÃ³digo**: Se solicitÃ³ asistencia para estructurar el cÃ³digo de scraping, manejo de excepciones y almacenamiento en JSON/CSV.
- **OptimizaciÃ³n de cÃ³digo**: Se refinÃ³ el manejo de errores y la eficiencia del proceso de scraping.
- **DepuraciÃ³n**: Se usÃ³ IA para diagnosticar errores en la configuraciÃ³n de Maven y la integraciÃ³n de dependencias.

Hemos seguido un enfoque de *Pair Programming*, donde uno de nosotros interactuaba con la IA mientras el otro revisaba y ajustaba la lÃ³gica segÃºn las necesidades del proyecto.

## ğŸ“Š Pruebas y Resultados
- Se realizaron pruebas finales verificando que el scraper funciona correctamente.
- Se comprobaron diferentes escenarios, incluyendo pÃ¡ginas sin productos y errores de conexiÃ³n.
- Se asegurÃ³ que los archivos JSON y CSV se actualicen correctamente cada hora.

---
Este proyecto ha sido realizado con la ayuda de la inteligencia artificial, cumpliendo asÃ­ los requisitos especificados en el mÃ³dulo de DigitalizaciÃ³n (1Âº CFGS - Desarrollo de Aplicaciones Multiplataforma). ğŸ§‘ğŸ»â€ğŸ’»
